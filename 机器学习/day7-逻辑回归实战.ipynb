{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集:社交网络\n",
    "![avatar](../image/机器学习_逻辑回归实战_社交网络.jpg)\n",
    "\n",
    "该数据集包含了社交网络中用户的信息。这些信息涉及用户ID,性别,年龄以及预估薪资。一家汽车公司刚刚推出了他们新型的豪华SUV，我们尝试预测哪些用户会购买这种全新SUV。并且在最后一列用来表示用户是否购买。我们将建立一种模型来预测用户是否购买这种SUV，该模型基于两个变量，分别是年龄和预计薪资。因此我们的特征矩阵将是这两列。我们尝试寻找用户年龄与预估薪资之间的某种相关性，以及他是否购买SUV的决定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相关库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "dataset=pd.read_csv('datasets/Social_Network_Ads.csv')\n",
    "X=dataset.iloc[:,[2,3]].values\n",
    "Y=dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关于使用sklearn进行数据预处理---标准化/归一化\n",
    "\n",
    "参考:[关于使用sklearn进行数据预处理---归一化/标注化/正则化](https://www.cnblogs.com/chaosimple/p/4153167.html)\n",
    "\n",
    "* 标准化(zero-mean normalization)\n",
    "公式为$(X-mean)/std$,计算时对每个属性/每列分别进行。\n",
    "\n",
    "标准化的结果是**对于每个属性/每列来说所有数据的均值为0，标准差为1。**\n",
    "\n",
    "数据的标准化（normalization）是将**数据按比例缩放，使之落入一个小的特定区间**。在某些比较和评价的指标处理中经常会用到，**去除数据的单位限制，将其转化为无量纲的纯数值**，便于不同单位或量级的指标能够进行比较和加权。\n",
    "\n",
    "在实现时，推荐使用`sklearn.preprocessing.StandardScaler`类，使用该类的好处在于可以保存训练集中的参数(均值、方差)。\n",
    "```python\n",
    ">>> from sklearn import preprocessing\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[ 1., -1.,  2.],\n",
    "...               [ 2.,  0.,  0.],\n",
    "...               [ 0.,  1., -1.]])\n",
    ">>> scaler = preprocessing.StandardScaler().fit(X)\n",
    ">>> scaler\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    " \n",
    ">>> scaler.mean_                                      \n",
    "array([ 1. ...,  0. ...,  0.33...])\n",
    " \n",
    ">>> scaler.std_                                       \n",
    "array([ 0.81...,  0.81...,  1.24...])\n",
    " \n",
    ">>> scaler.transform(X)                               \n",
    "array([[ 0.  ..., -1.22...,  1.33...],\n",
    "       [ 1.22...,  0.  ..., -0.26...],\n",
    "       [-1.22...,  1.22..., -1.06...]])\n",
    " \n",
    " \n",
    ">>>#可以直接使用训练集对测试集数据进行转换\n",
    ">>> scaler.transform([[-1.,  1., 0.]])                \n",
    "array([[-2.44...,  1.22..., -0.26...]])\n",
    "```\n",
    "\n",
    "* 归一化(Min-max normalization)\n",
    "归一化将属性缩放到一个指定的最大和最小值(通常是1-0)之间，其中缩放到1-0之间时称为归一化。\n",
    "\n",
    "其公式为$(x-min)/(max-min)$,max为样本最大值，min为样本最小值。**缺点是当有新数据加入时需要重新进行数据归一化。**\n",
    "\n",
    "在实现时，采用`sklearn.preprocessing.MinMaxScaler`类实现。\n",
    "```python\n",
    ">>> X_train = np.array([[ 1., -1.,  2.],\n",
    "...                     [ 2.,  0.,  0.],\n",
    "...                     [ 0.,  1., -1.]])\n",
    "...\n",
    ">>> min_max_scaler = preprocessing.MinMaxScaler()\n",
    ">>> X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    ">>> X_train_minmax\n",
    "array([[ 0.5       ,  0.        ,  1.        ],\n",
    "       [ 1.        ,  0.5       ,  0.33333333],\n",
    "       [ 0.        ,  1.        ,  0.        ]])\n",
    " \n",
    ">>> #将相同的缩放应用到测试集数据中\n",
    ">>> X_test = np.array([[ -3., -1.,  4.]])\n",
    ">>> X_test_minmax = min_max_scaler.transform(X_test)\n",
    ">>> X_test_minmax\n",
    "array([[-1.5       ,  0.        ,  1.66666667]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征缩放\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "逻辑回归是一个线性分类器，这意味着在二维空间中，我们两类用户将被一条直线分割。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  3]\n",
      " [ 8 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#生成混淆矩阵\n",
    "cm = confusion_matrix(Y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
