{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMO算法\n",
    "\n",
    "参考:\n",
    "1.[快速理解SMO算法](https://www.bilibili.com/video/BV1bK4y187hG?from=search&seid=16299104060004525552)\n",
    "2.李航《统计学习方法》\n",
    "\n",
    "前面我们已经知道，SVM要求解的问题是:\n",
    "\\begin{array}{ll}\n",
    "\\max_{\\alpha} & L(\\alpha)=\\sum_{i=1}^{n} \\alpha_{i}-\\frac{1}{2} \\sum_{i, j=1}^{n} \\alpha_{i} \\alpha_{j} y_{i} y_{j} \\kappa\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)\\\\\n",
    "\\text { s.t. } & 0 \\le \\alpha_{i} \\le C \\\\\n",
    "& \\Sigma_{i=1}^{m}a_iy_i=0 \\\\\n",
    "\\end{array}\n",
    "\n",
    "SMO（序列最小最优化算法）算法是一种启发式算法，其基本思路是：\n",
    "如果所有变量的解都满足次最优化问题的KKT条件，那么这个最优化问题的解就得到了。SMO算法选择两个变量，同时固定其他变量来求解问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义$\\kappa\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)=\\kappa_{ij}$,假设选择的两个变量是$\\alpha_1,\\alpha_2$,其他变量$\\alpha_i(i=3,4,..N)$是固定的，于是SMO的最优化问题可写成:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min _{\\alpha_{1}, \\alpha_{2}} W\\left(\\alpha_{1}, \\alpha_{2}\\right)=& \\frac{1}{2} K_{11} \\alpha_{1}^{2}+\\frac{1}{2} K_{22} \\alpha_{2}^{2}+y_{1} y_{2} K_{12} \\alpha_{1} \\alpha_{2} \\\\\n",
    "&-\\left(\\alpha_{1}+\\alpha_{2}\\right)+y_{1} \\alpha_{1} \\sum_{i=3}^{N} y_{i} \\alpha_{i} K_{i 1}+y_{2} \\alpha_{2} \\sum_{i=3}^{N} y_{i} \\alpha_{i} K_{i 2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text { s.t. } \\quad \\alpha_{1} y_{1}+\\alpha_{2} y_{2}=-\\sum_{i=3}^{N} y_{i} \\alpha_{i}=\\zeta\\\\\n",
    "&0 \\leqslant \\alpha_{i} \\leqslant C, \\quad i=1,2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 考虑约束\n",
    "\n",
    "首先分析约束条件，然后在此约束条件下求极小。\n",
    "\n",
    "由于只有两个变量$(\\alpha_1,\\alpha_2)$,由于$\\alpha_{1} y_{1}+\\alpha_{2} y_{2}=\\zeta$,所以我们对$y_1,y_2$的取值分别讨论分析:\n",
    "##### 情况1：$y_1=1,y_2=1$\n",
    "![avatar](../image/机器学习_支持向量机_图4.jpg)\n",
    "当$y_1=1,y_2=1$时，此时$\\alpha_2=\\zeta-\\alpha_1$直线斜率为$-1$,同时分析可知，由于$0 \\le \\alpha_1+\\alpha_2 \\le 2C$.\n",
    "\n",
    "1. 当$0 \\le \\zeta \\le C$时，所得的直线如图中的蓝线所示，此时1点坐标为$(\\zeta,0)$,2点坐标为$(0,\\zeta)$,此时$\\alpha2$可能的取值为蓝色部分，即$\\alpha2 \\in [0,\\zeta]$\n",
    "\n",
    "2. 当$C \\le \\zeta \\le C$时，所得的直线如图中的红线所示，此时3点的坐标为$(C,\\zeta-C)$,4点的坐标为$(\\zeta-C,C)$,此时$\\alpha_2$可能的取值为红色部分，即 $\\alpha_2 \\in [\\zeta-C,C]$\n",
    "\n",
    "由于$\\alpha^{old}_1+\\alpha^{old}_2=\\zeta$,其中$\\alpha^{old}_1,\\alpha^{old}_2$是旧的值.所以综上两点分析可得$\\alpha^{new}_2$的取值范围为:\n",
    "$$\n",
    "max(0,\\alpha^{old}_1+\\alpha^{old}_2-C) \\le \\alpha^{new}_2 \\le min(\\alpha^{old}_1+\\alpha^{old}_2,C)\n",
    "$$\n",
    "\n",
    "##### 情况2：$y_1=1,y_2=-1$\n",
    "![avatar](../image/机器学习_支持向量机_图5.jpg)\n",
    "此时$\\alpha^{old}_1-\\alpha^{old}_2=\\zeta$,同理分析可得$\\alpha_2$的取值范围为:\n",
    "$$\n",
    "max(0,\\alpha^{old}_2-\\alpha^{old}_1) \\le \\alpha^{new}_2 \\le min(C,C+\\alpha^{old}_2-\\alpha^{old}_1)\n",
    "$$\n",
    "\n",
    "##### 情况3：$y_1=-1,y=-1$\n",
    "\n",
    "结果同$y_1=1,y_2=1$\n",
    "\n",
    "##### 情况4：$y_1=-1,y_2=1$\n",
    "\n",
    "结果同$y_1=1,y_2=-1$\n",
    "\n",
    "对上面四种情况进行总结，我们令:\n",
    "$$\n",
    "L \\le \\alpha^{new}_2 \\le H\n",
    "$$\n",
    "当$y_1=y_2$,则\n",
    "$$\n",
    "L=max(0,\\alpha^{old}_1+\\alpha^{old}_2-C),\n",
    "H=min(\\alpha^{old}_1+\\alpha^{old}_2,C)\n",
    "$$\n",
    "当$y_1!=y_2$,则\n",
    "$$\n",
    "L=max(0,\\alpha^{old}_2-\\alpha^{old}_1),\n",
    "H=min(C,C+\\alpha^{old}_2-\\alpha^{old}_1)\n",
    "$$\n",
    "\n",
    "也就是对接下来求解得到的$\\alpha^{new,unc}_2$处理为:\n",
    "$$\n",
    "\\alpha_{2}^{\\text {new}}=\\left\\{\\begin{array}{ll}\n",
    "H & \\alpha_{2}^{\\text {new,unc}}>H \\\\\n",
    "\\alpha_{2}^{\\text {new,unc}} & L \\leq \\alpha_{2}^{\\text {new}, u n c} \\leq H \\\\\n",
    "L & \\alpha_{2}^{\\text {new}, u n c}<L\n",
    "\\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 求解$\\alpha_2$\n",
    "\n",
    "那么要如何求解$\\alpha^{new,unc}_2$呢，很简单，由$\\alpha_{1} y_{1}=\\zeta-\\alpha_{2} y_{2}$ 及 $y_{i}^{2}=1,$ 可将 $\\alpha_{1}$ 表示成\n",
    "$$\n",
    "\\alpha_{1}=\\left(\\zeta-y_{2} \\alpha_{2}\\right) y_{1}\n",
    "$$,将$W(\\alpha_1,\\alpha_2)$中的$\\alpha_1$消去，之后我们只需要对目标函数$W(\\alpha_2)$求偏导取零即可得。\n",
    "\n",
    "最终求解得到的未经裁剪的解是:\n",
    "$$\n",
    "\\alpha_{2}^{\\text {new, }\\text { unc }}=\\alpha_{2}^{\\text {old }}+\\frac{y_{2}\\left(E_{1}-E_{2}\\right)}{\\eta}\n",
    "$$\n",
    "其中\n",
    "$$\n",
    "E_{1}=y1-f(x_1)\n",
    "$$\n",
    "$$\n",
    "E_{2}=y2-f(x_2)\n",
    "$$\n",
    "$$\n",
    "\\eta=K_{11}+K_{22}-2 K_{12}\n",
    "$$\n",
    "$E_{1},E{2}$即真实值与预测值之间的误差。\n",
    "\n",
    "具体推导过程参考李航《统计学习方法》p127~128.\n",
    "\n",
    "之后对$\\alpha_{2}^{\\text {new, }\\text { unc }}$裁剪后得到$\\alpha^{new}_2$,然后通过式子\n",
    "$$\n",
    "\\alpha^{new}_{1}=\\left(\\zeta-y_{2} \\alpha^{new}_{2}\\right) y_{1}\n",
    "$$\n",
    "即可得$\\alpha^{new}_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 变量的选择方法\n",
    "\n",
    "SMO算法每次选择两个变量优化，其中至少一个变量是违反KKT条件的。\n",
    "\n",
    "##### 第1个变量的选择\n",
    "\n",
    "SMO 称选择第 1 个变量的过程为外层循环。外层循环在训练样本中选取违 反 KKT 条件最严重的样本点，并将其对应的变量作为第 1 个变量。具体地，检 验训练样本点 ( $\\left.x_{i}, y_{i}\\right)$ 是否满足 $\\mathrm{KKT}$ 条件(主要根据松弛互补条件)，即\n",
    "$$\n",
    "\\alpha_{i}=0 \\Leftrightarrow y_{i} f\\left(x_{i}\\right) \\geqslant 1\n",
    "$$\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "0<\\alpha_{i}<C \\Leftrightarrow y_{i} f\\left(x_{i}\\right)=1 \\\\\n",
    "\\alpha_{i}=C \\Leftrightarrow y_{i} f\\left(x_{i}\\right) \\leqslant 1\n",
    "\\end{array}\n",
    "$$\n",
    "$$\n",
    "其中, f\\left(x_{i}\\right)=\\sum_{j=1}^{N} \\alpha_{j} y_{j} K\\left(x_{i}, x_{j}\\right)+b\n",
    "$$\n",
    "该检验是在 $\\varepsilon$ 范围内进行的。在检验过程中，外层循环首先遍历所有满足条 件 $0<\\alpha_{i}<C$ 的样本点，即在间隔边界上的支持向量点，检验它们是否满足 KKT 条件。如果这些样本点都满足 KKT 条件，那么遍历整个训练集，检验它们是否 满足 KKT 条件。\n",
    "\n",
    "##### 第2个变量的选择\n",
    "SMO 称选择第 2 个变量的过程为内层循环. 假设在外层循环中已经找到第 1 个变量 $\\alpha_{1},$ 现在要在内层循环中找第 2 个变量 $\\alpha_{2} .$ 第 2 个变量选择的标准是希望 能使 $\\alpha_{2}$ 有足够大的变化.\n",
    "\n",
    "一种简单的做法是选择 $\\alpha_{2},$ 使其对应的 $\\left|E_{1}-E_{2}\\right|$ 最大. 为了节省计算时间，将所有 $E_{i}$ 值保存在一个列表中. \n",
    "\n",
    "在特殊情况下，如果内层循环通过以上方法选择的 $\\alpha_{2}$不能使目标函数有足够的下降, 那么遍历在间隔边界上的支持向量点, 依次将其对应的变量作为 $\\alpha_{2}$ 试用，直到目标函数有足够的下降. 若找不到合适的\n",
    "$\\alpha_{2},$ 那么遍历整个训练数据集; 若仍找不到合适的 $\\alpha_{2},$ 则放弃第1个 $\\alpha_{1},$ 再通过外层循环寻求另外的$\\alpha_{1}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算b和差值$E_1$\n",
    "\n",
    "在每次完成两个变量的优化后，都要重新计算闻值 b . 当 $0<\\alpha_{1}^{\\text {new }}<C$ 时，由 KKT 条件 (松弛互补条件) 可知:\n",
    "$$\n",
    "\\sum_{i=1}^{N} \\alpha_{i} y_{i} K_{i 1}+b=y_{1}\n",
    "$$\n",
    "于是，\n",
    "$$\n",
    "b_{1}^{\\text {rew }}=y_{1}-\\sum_{i=3}^{N} \\alpha_{i} y_{i} K_{i 1}-\\alpha_{1}^{\\text {new }} y_{1} K_{11}-\\alpha_{2}^{\\text {new }} y_{2} K_{21}\n",
    "$$\n",
    "由 $E_{1}$ 的定义式有\n",
    "$$\n",
    "E_{1}=\\sum_{i=3}^{N} \\alpha_{i} y_{i} K_{i 1}+\\alpha_{1}^{\\mathrm{old}} y_{1} K_{\\mathrm{I}}+\\alpha_{2}^{\\mathrm{old}} y_{2} K_{21}+b^{\\mathrm{old}}-y_{1}\n",
    "$$\n",
    "\n",
    "$b_1^{new}$的前两项可写成:\n",
    "$$\n",
    "y_{1}-\\sum_{i=3}^{N} \\alpha_{i} y_{i} K_{i 1}=-E_{1}+\\alpha_{1}^{\\text {old }} y_{1} K_{11}+\\alpha_{2}^{\\text {old }} y_{2} K_{21}+b^{\\text {old }}\n",
    "$$\n",
    "代入式子，可得\n",
    "\n",
    "\n",
    "$$\n",
    "b_{1}^{\\text {new }}=-E_{1}-y_{1} K_{11}\\left(\\alpha_{1}^{\\text {new }}-\\alpha_{1}^{\\text {old }}\\right)-y_{2} K_{21}\\left(\\alpha_{2}^{\\text {new }}-\\alpha_{2}^{\\text {old }}\\right)+b^{\\text {old }}\n",
    "$$\n",
    "\n",
    "\n",
    "同样，如果 $0<\\alpha_{2}^{\\text {new }}<C,$ 那么,\n",
    "\n",
    "\n",
    "$$\n",
    "b_{2}^{\\text {new }}=-E_{2}-y_{1} K_{12}\\left(\\alpha_{1}^{\\text {new }}-\\alpha_{1}^{\\text {old }}\\right)-y_{2} K_{22}\\left(\\alpha_{2}^{\\text {new }}-\\alpha_{2}^{\\text {old }}\\right)+b^{\\text {old }}\n",
    "$$\n",
    "\n",
    "\n",
    "如果 $\\alpha_{1}^{\\text {new }}, \\alpha_{2}^{\\text {new }}$ 同时满足条件 $0<\\alpha_{i}^{\\text {new }}<C, \\quad i=1,2, \\quad$ 那么 $b_{1}^{\\text {new }}=b_{2}^{\\text {new }} .$ 如果 $\\alpha_{1}^{\\text {new }}, \\alpha_{2}^{\\text {new }}$ 是 0 或者 $C,$ 那么 $b_{1}^{\\text {now }}$ 和 $b_{2}^{\\text {new }}$ 以及它们之间的数都是符合 $\\mathrm{KKT}$ 条件的阈\n",
    "值，这时选择它们的中点作为 $b ^{ new }$.\n",
    "\n",
    "在每次完成两个变量的优化之后，还必须更新对应的 $E_{i}$ 值，并将它们保存在列表中。 $E_{i}$ 值的更新要用到 $b^{\\text {new }}$ 值，以及所有支持向量对应的 $\\alpha_{j}$\n",
    "$$\n",
    "E_{i}^{\\text {new }}=\\sum_{s} y_{j} \\alpha_{j} K\\left(x_{i}, x_{j}\\right)+b^{\\text {new }}-y_{i}\n",
    "$$\n",
    "其中， $S$ 是所有支持向量 $x_{j}$ 的集合."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMO算法总结\n",
    "\n",
    "输\n",
    "$\\lambda:$ 训练数据集 $T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\},$ 其中, $x_{i} \\in \\mathcal{X}=\\mathbf{R}^{n}, \\quad y_{i} \\in$\n",
    "$\\mathcal{Y}=\\{-1,+1\\}, \\quad i=1,2, \\cdots, N, \\quad$ 精度 $\\boldsymbol{\\varepsilon}$\n",
    "\n",
    "\n",
    "输出：近似解 $\\hat{\\alpha}$\n",
    "\n",
    "\n",
    "（1）取初值 $\\alpha^{(0)}=0, \\quad$ 令 $k=0$\n",
    "\n",
    "\n",
    "（2）选取优化变量 $\\alpha_{1}^{(k)}, \\alpha_{2}^{(k)},$ 解析求解两个变量的最优化问题，求得最优解 $\\alpha_{1}^{(k+1)}, \\alpha_{2}^{(k+1)}, \\quad$ 更新 $\\alpha$ 为 $\\alpha^{(k+1)}$，更新$b$，更新$E_i$\n",
    "\n",
    "\n",
    "（3）若在精度 $\\varepsilon$ 范围内满足停机条件\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\sum_{i=1}^{N} \\alpha_{i} y_{i}=0 \\\\\n",
    "0 \\leqslant \\alpha_{i} \\leqslant C, \\quad i=1,2, \\cdots, N \\\\\n",
    "y_{i} \\cdot f\\left(x_{i}\\right)=\\left\\{\\begin{array}{ll}\n",
    "\\geqslant 1, & \\left\\{x_{i} \\mid \\alpha_{i}=0\\right\\} \\\\\n",
    "=1, & \\left\\{x_{i} \\mid 0<\\alpha_{i}<C\\right\\} \\\\\n",
    "\\leqslant 1, & \\left\\{x_{i} \\mid \\alpha_{i}=C\\right\\}\n",
    "\\end{array}\\right.\n",
    "\\end{array}\n",
    "$$\n",
    "其中，\n",
    "$$\n",
    "f\\left(x_{i}\\right)=\\sum_{j=1}^{N} \\alpha_{j} y_{j} K\\left(x_{j}, x_{i}\\right)+b\n",
    "$$\n",
    "则转(4) ; 否则令 $k=k+1,$ 转 (2);\n",
    "\n",
    "\n",
    " (4) 取 $\\hat{\\alpha}=\\alpha^{(k+1)}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
