{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提升方法AdaBoost算法\n",
    "\n",
    "提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器（又称为基本分类器），然后组合这些弱分类器，构成一个强分类器。大多数的提升方法都是改变训练数据的概率分布（训练数据的权重分布），针对不同的训练数据分布调用弱学习算法学习一系列弱分类器。\n",
    "\n",
    "对于提升方法来说，有两个问题需要回答：\n",
    "1. 如何在每一轮改变训练数据的权值或概率分布\n",
    "2. 如何将弱分类器组合成一个强分类器\n",
    "\n",
    "#### 符号定义\n",
    "\n",
    "假设给定一个二类分类的训练数据集\n",
    "$$\n",
    "T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}\n",
    "$$\n",
    "其中，每个样本点由实例与标记组成。实例 $x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n},$ 标记 $y_{i} \\in \\mathcal{Y}=\\{-1,+1\\}$\n",
    ",$\\mathcal{X}$ 是实例空间， $\\mathcal{Y}$是标记集合."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost算法\n",
    "\n",
    "输入：训练数据集 $T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\},$ 其中 $x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}, \\quad y_{i} \\in$\n",
    "$\\mathcal{Y}=\\{-1,+1\\} ;$ 弱学习算法:\n",
    "输出：鬆终分类器 $G(x)$\n",
    "1. 初始化训练数据的权值分布\n",
    "\n",
    "$$\n",
    "D_{1}=\\left(w_{11}, \\cdots, w_{1 i}, \\cdots, w_{1 N}\\right), \\quad w_{1 i}=\\frac{1}{N}, \\quad i=1,2, \\cdots, N\n",
    "$$\n",
    "\n",
    "2. 对$m=1,2, \\cdots, M$:\n",
    "\n",
    "\n",
    "* 使用具有权值分布$D_m$的训练数据集学习，得到基本分类器\n",
    "    \n",
    "$$\n",
    "G_{m}(x): \\mathcal{X} \\rightarrow\\{-1,+1\\}\n",
    "$$\n",
    "* 计算$G_m(x)$在训练数据集上的分类误差率\n",
    "    \n",
    "$$\n",
    "e_{m}=P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)\n",
    "$$\n",
    "\n",
    "* 计算 $G_{m}(x)$ 的系数\n",
    "    \n",
    "$$\n",
    "\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}\n",
    "$$\n",
    "\n",
    "这里的对数是自然对数。\n",
    "\n",
    "* 更新训练数据集的权值分布\n",
    "    \n",
    "$$\n",
    "\\begin{array}{c}\n",
    "D_{m+1}=\\left(w_{m+1,1}, \\cdots, w_{m+1, i}, \\cdots, w_{m+1, N}\\right) \\\\\n",
    "w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, N\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "这里， Z $_{m}$ 是规范化因子\n",
    "\n",
    "$$\n",
    "Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)\n",
    "$$\n",
    "\n",
    "它使 $D_{m+1}$ 成为一个概率分布.\n",
    "3. 构建基本分类器的线性组合\n",
    "\n",
    "$$\n",
    "f(x)=\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)\n",
    "$$\n",
    "\n",
    "得到最终分类器\n",
    "\n",
    "$$\n",
    "G(x)=\\operatorname{sign}(f(x))=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)\\right)\n",
    "$$\n",
    "\n",
    "其中$sign$函数为:\n",
    "$$\n",
    "\\operatorname{sign}(x)=\\left\\{\\begin{array}{ll}\n",
    "1, & x>0 \\\\\n",
    "0, & x=0 \\\\\n",
    "-1, & x<0\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost算法针对前面两个问题的处理方式是:\n",
    "1. 改变权值方式：提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注. \n",
    "2. 弱分类器的组合方式：AdaBoost 采取加权多数表决的方法。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，減小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。\n",
    "\n",
    "\n",
    "实例参考李航《统计学习方法》p140~142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost算法的训练误差分析\n",
    "\n",
    "AdaBoost算法最终分类器的训练误差界为\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^{N} I\\left(G\\left(x_{i}\\right) \\neq y_{i}\\right) \\leqslant \\frac{1}{N} \\sum_{i} \\exp \\left(-y_{i} f\\left(x_{i}\\right)\\right)=\\prod_{m} Z_{m}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
