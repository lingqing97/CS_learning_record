{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn.ensemble.AdaboostClassifier介绍\n",
    "\n",
    "class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "\n",
    "参数:\n",
    "* base_estimator:默认为None，即选择CART决策树,也可以选择其他支持样本权重的分类模型\n",
    "* random_state:随机数生成器参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost算法从零实现\n",
    "\n",
    "AdaBoost算法的优缺点如下:\n",
    "* 优点：泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整\n",
    "* 缺点：对离散点敏感"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于单层决策树构建弱分类器\n",
    "\n",
    "单层决策树是一种简单的决策树，它仅基于单个特征来做决策，只有一次分裂过程。通过使用多棵单层决策树，我们就可以构建出一个能过对该数据集完全正确分类的强分类器。\n",
    "\n",
    "构建单层决策树的伪代码如下:\n",
    "* 将最小错误率minError设为+$\\infty$ \n",
    "    * 对数据集中的每一个特征（第一层循环 ):\n",
    "        * 对每个步长（第二层循环 ):\n",
    "            * 对每个不等号（第三层循环）:\n",
    "                * 建立一棵单层决策树并利用加权数据集对它进行测试 \n",
    "                * 如果错误率低于minError，则将当前单层决策树设为最佳单层决策树 \n",
    "* 返回最佳单层决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMat,dimen,threshVal,threshIneq):\n",
    "    '''\n",
    "    通过阈值对数据进行分类\n",
    "    Args:\n",
    "        dataMat(narray):输入数据,shape(m,n)\n",
    "        dimen(int):分类依据的属性下标\n",
    "        threshVal(float):阈值\n",
    "        threshIneq(str):比较的方式,'lt'表示小于等于阈值判为负例\n",
    "    Returns:\n",
    "        retArray(narray):分类后的标记数据,shape(m,1)\n",
    "    '''\n",
    "    retArray=np.ones((dataMat.shape[0],1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMat[:,dimen]<=threshVal]=-1.0\n",
    "    else:\n",
    "        retArray[dataMat[:,dimen]>threshVal]=-1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataMat,classLabels,D):\n",
    "    '''\n",
    "    基于数据的权重构建最佳的单层决策树\n",
    "    Args:\n",
    "        dataMat(narray):输入数据,shape(m,n)\n",
    "        classLabels(narray):标签数据,shape(1,m)\n",
    "        D(narray):权重向量,shape(m,1)\n",
    "    Returns:\n",
    "        bestStump:记录最佳决策树的相关参数\n",
    "        minError:最佳决策树的分类误差率\n",
    "        bestClassEst:最佳决策树的分类结果\n",
    "    '''\n",
    "    m,n=dataMat.shape\n",
    "    labelMat=classLabels.reshape((m,1))\n",
    "    numSteps=10.0    #步长\n",
    "    bestStump={}   #通过字典记录最佳单层决策树的相关参数\n",
    "    bestClassEst=np.zeros((m,1))   #记录最佳决策树的分类结果\n",
    "    minError=np.inf\n",
    "    for i in range(n):\n",
    "        rangeMin=dataMat[:,i].min()\n",
    "        rangeMax=dataMat[:,i].max()\n",
    "        stepSize=(rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1):\n",
    "            threshVal=rangeMin+j*stepSize\n",
    "            for inequal in ['lt','gt']: #遍历小于和大于阈值两种情况\n",
    "                predictVals=stumpClassify(dataMat,i,threshVal,inequal)\n",
    "                errArr=np.ones((m,1))\n",
    "                errArr[labelMat==predictVals]=0\n",
    "                #计算分类误差率\n",
    "                weightError=np.dot(D.T,errArr)\n",
    "                if weightError<minError:\n",
    "                    minError=weightError\n",
    "                    bestClassEst=predictVals.copy()\n",
    "                    bestStump['dim']=i\n",
    "                    bestStump['thresh']=threshVal\n",
    "                    bestStump['ineq']=inequal\n",
    "\n",
    "    return bestStump,minError,bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'},\n",
       " array([[0.2]]),\n",
       " array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试\n",
    "dataMat=np.array([[1.0,2.1],[2.0,1.1],[1.3,1.0],[1.0,1.0],[2.0,1.0]])\n",
    "classLabels=np.array([1.0,1.0,-1.0,-1.0,1.0])\n",
    "D=np.ones((5,1))/5\n",
    "buildStump(dataMat,classLabels,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面得到就是一个弱学习器，接下来我们使用多个弱分类器来构建AdaBoost。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost算法完整实现\n",
    "\n",
    "AdaBoost实现的伪代码如下：\n",
    "* 对每次迭代：\n",
    "    * 利用buildStump()函数找到最佳的单层决策树 \n",
    "    * 将最佳单层决策树加入到单层决策树数组\n",
    "    * 计算alpha \n",
    "    * 计算新的权重向量D\n",
    "    * 更新累计类别估计值 \n",
    "    * 如果错误率等于0.0，则退出循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    '''\n",
    "    adaBoost训练函数\n",
    "    Args:\n",
    "        dataArr(narray):输入数据,shape(m,n)\n",
    "        classLabels(narray):输入数据,shape(1,m)\n",
    "        numIt(int):最大迭代次数\n",
    "    Returns:\n",
    "        weakClassArr:弱决策器数组\n",
    "    '''\n",
    "    weakClassArr=[]  #弱决策器数组\n",
    "    m=dataArr.shape[0]\n",
    "    D=np.ones((m,1))/m  #初始化权重参数\n",
    "    aggClassEst=np.zeros((m,1))\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst=buildStump(dataArr,classLabels,D)\n",
    "        print(\"D:\",D.T)\n",
    "        alpha=0.5*np.log((1.0-error)/max(error,1e-16))\n",
    "        bestStump['alpha']=alpha[0][0]\n",
    "        #将当前若分类器添加进数组\n",
    "        weakClassArr.append(bestStump)\n",
    "        print(\"classEst:\",classEst.T)\n",
    "        #更新权重\n",
    "        expon=-1*alpha*(classLabels.reshape(m,1))*classEst\n",
    "        D=D*np.exp(expon)\n",
    "        D=D/D.sum()\n",
    "        #获取当前弱决策器预测结果在最终结果中所占比重\n",
    "        aggClassEst+=alpha*classEst\n",
    "        print(\"aggClassEst:\",aggClassEst.T)\n",
    "        #计算累加错误率\n",
    "        #np.sign函数取数字符号的函数\n",
    "        aggErrors=(np.sign(aggClassEst)!=(classLabels.reshape((m,1)))).astype(int)\n",
    "        errorRate=aggErrors.sum()/m\n",
    "        print(\"total error:\",errorRate)\n",
    "        if errorRate==0.0:\n",
    "            #错误率等于0，退出循环\n",
    "            break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst: [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst: [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error: 0.2\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst: [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst: [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error: 0.2\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst: [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst: [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error: 0.0\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "classifierArray=adaBoostTrainDS(dataMat,classLabels,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于AdaBoost的分类\n",
    "def adaClassify(dataMat,classifierArray):\n",
    "    '''\n",
    "    基于AdaBoost的分类函数\n",
    "    Args:\n",
    "        dataMat(narray):预测数据,shape(m,n)\n",
    "        classifierArray(narray):弱分类器数组\n",
    "    Returns:\n",
    "        sign(aggClassEst):分类结果,shape(m,1)\n",
    "    '''\n",
    "    m=dataMat.shape[0]\n",
    "    aggClassEst=np.zeros((m,1))\n",
    "    for i in range(len(classifierArray)):\n",
    "        classEst=stumpClassify(dataMat,classifierArray[i]['dim'],\n",
    "                              classifierArray[i]['thresh'],\n",
    "                              classifierArray[i]['ineq'])\n",
    "        aggClassEst+=classifierArray[i]['alpha']*classEst\n",
    "        print(\"aggClassEst:\",aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggClassEst: [[-0.69314718]]\n",
      "aggClassEst: [[-1.66610226]]\n",
      "aggClassEst: [[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试\n",
    "adaClassify(np.array([[0,0]]),classifierArray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
